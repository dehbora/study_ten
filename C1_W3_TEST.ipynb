{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJjxX5c/qiqfI5woKtmm7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dehbora/study_ten/blob/tensorflow-certificate/C1_W3_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fP3JEORGtPS"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: This will check your notebook's metadata for grading.\n",
        "# Please do not continue the lab unless the output of this cell tells you to proceed. \n",
        "!python add_metadata.py --filename C1W3_Assignment.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "-HV1lj1yG1bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Load the data\n",
        "\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n"
      ],
      "metadata": {
        "id": "tpGzSwn8G3Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape(60000,28,28,1)\n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images / 255.0\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "ifsHTwXkG4-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
      ],
      "metadata": {
        "id": "GLWwKPZrG6lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the method that checks the accuracy at the end of each epoch\n",
        "    def on_epoch_end(self, epochs, logs={}):\n",
        "        if (logs.get('accuracy')>0.995):\n",
        "            print('accuracy reached 99.5% stop!!')\n",
        "            self.model.stop_training = True\n",
        "                      \n",
        "### END CODE HERE\n"
      ],
      "metadata": {
        "id": "MGSFmYWuG9z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "  # Add the same layers as before\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')      \n",
        "    ])\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "_MNHp_MRG_8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Get number of weights\n",
        "model_params = model.count_params()\n",
        "\n",
        "# Unit test to limit the size of the model\n",
        "assert model_params < 1000000, (\n",
        "    f'Your model has {model_params:,} params. For successful grading, please keep it ' \n",
        "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
        ")\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "6a3Ez7W1HCRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
      ],
      "metadata": {
        "id": "sxU5PprUHEiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not \"accuracy\" in history.model.metrics_names:\n",
        "    print(\"Use 'accuracy' as metric when compiling your model.\")\n",
        "else:\n",
        "    print(\"The metric was correctly defined.\")"
      ],
      "metadata": {
        "id": "-ibifzmzHGHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function and an input shape that matches that of every image in the training set\n",
        "   - A MaxPooling2D layer with a pool_size of 2x2\n",
        "   - A Flatten layer with no arguments\n",
        "   - A Dense layer with 128 units and ReLU activation function\n",
        "   - A Dense layer with 10 units and softmax activation function\n"
      ],
      "metadata": {
        "id": "Frwl481kHqfI"
      }
    }
  ]
}